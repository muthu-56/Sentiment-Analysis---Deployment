{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "#Data handling\n",
    "import pandas as pd \n",
    "\n",
    "#For data preprocessing\n",
    "from textblob import TextBlob #\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#For data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Training and testing data split\n",
    "from sklearn.pipeline import Pipeline #Model pipeline\n",
    "from sklearn.model_selection import GridSearchCV #Parameter tuning\n",
    "import joblib #To dump trained models\n",
    "import pickle #To store data in bytes\n",
    "\n",
    "#Models and metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>A littly iffy on the controls, but once you kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Great game, fun and colorful and all that.A si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Not many games have the cute tag right next to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Early Access ReviewIt's pretty cute at first, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Great game. it's a cute little horror game tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Spooky's Jump Scare Mansion is a Free Retro ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Somewhere between light hearted, happy parody ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>This game with its cute little out of the wall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
       "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
       "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
       "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
       "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
       "5          6  Spooky's Jump Scare Mansion  2015.0   \n",
       "6          7  Spooky's Jump Scare Mansion  2017.0   \n",
       "7          8  Spooky's Jump Scare Mansion  2015.0   \n",
       "8          9  Spooky's Jump Scare Mansion  2015.0   \n",
       "9         10  Spooky's Jump Scare Mansion  2015.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
       "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
       "2  A littly iffy on the controls, but once you kn...                1  \n",
       "3  Great game, fun and colorful and all that.A si...                1  \n",
       "4  Not many games have the cute tag right next to...                1  \n",
       "5  Early Access ReviewIt's pretty cute at first, ...                1  \n",
       "6  Great game. it's a cute little horror game tha...                1  \n",
       "7  Spooky's Jump Scare Mansion is a Free Retro ma...                1  \n",
       "8  Somewhere between light hearted, happy parody ...                0  \n",
       "9  This game with its cute little out of the wall...                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to predict user suggestion only based on user_review. Hence drop Review_id, titile and year\n",
    "train=train[['user_review', 'user_suggestion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_review        0\n",
       "user_suggestion    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.569795\n",
       "0    0.430205\n",
       "Name: user_suggestion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the target class balance\n",
    "train.user_suggestion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This shows that our target class is not highly imbalanced. This data will help us to make good trainable model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(data): #function to remove Special characters like @#[]()!\n",
    "    tweet_blob = TextBlob(data)\n",
    "    words = tweet_blob.words\n",
    "    sent = ' '.join(words)\n",
    "    return sent \n",
    "\n",
    "train.user_review = train.user_review.apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_junk(data): #function to keep only characters and remove 'user'- which is not required \n",
    "    words=[words for words in data.split() if words != 'user']    \n",
    "    clean_tokens = [t for t in words if re.match(r'[^\\W\\d]*$', t)] # Remove punctuations')]\n",
    "    sent_join  = ' '.join(clean_tokens)\n",
    "    return sent_join\n",
    "\n",
    "train.user_review = train.user_review.apply(remove_junk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "train['user_review'] = train['user_review'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i scared hearing creepy voices so i pause mome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best game better sam pepper youtube account ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a littly iffy controls know play easy master i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great game fun colorful side note though when ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not many games cute tag right next horror tag ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_review  user_suggestion\n",
       "0  i scared hearing creepy voices so i pause mome...                1\n",
       "1  best game better sam pepper youtube account ne...                1\n",
       "2  a littly iffy controls know play easy master i...                1\n",
       "3  great game fun colorful side note though when ...                1\n",
       "4  not many games cute tag right next horror tag ...                1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing the words\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "train.user_review = train.user_review.apply(lemmatize_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i scared hearing creepy voice so i pause momen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best game better sam pepper youtube account ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a littly iffy control know play easy master i ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great game fun colorful side note though when ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not many game cute tag right next horror tag f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_review  user_suggestion\n",
       "0  i scared hearing creepy voice so i pause momen...                1\n",
       "1  best game better sam pepper youtube account ne...                1\n",
       "2  a littly iffy control know play easy master i ...                1\n",
       "3  great game fun colorful side note though when ...                1\n",
       "4  not many game cute tag right next horror tag f...                1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent and independent featuere\n",
    "X= train['user_review']\n",
    "y=train['user_suggestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Pipeline -- NB with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline(steps=[('tf', TfidfVectorizer()), ('NB', MultinomialNB())])\n",
    "\n",
    "# Create Parameter Grid\n",
    "pgrid_mnnb = {\n",
    "#  'tf__max_features' : [1000, 3000, 4000, 5000],\n",
    "#  'tf__stop_words' : ['english', None],\n",
    " 'tf__ngram_range' : [(1,1),(1,2), (2,2)],\n",
    " 'tf__use_idf' : [True, False],\n",
    " 'NB__alpha' : [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Apply GridSearch to Pipeline to find the best parameters\n",
    "gs_mnnb = GridSearchCV(pipe_nb, pgrid_mnnb, cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('NB', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'NB__alpha': [0.01, 0.1, 0.5, 1],\n",
       "                         'tf__max_features': [1000, 3000, 4000, 5000],\n",
       "                         'tf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
       "                         'tf__use_idf': [True, False]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "gs_mnnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NB__alpha': 0.1,\n",
       " 'tf__max_features': 5000,\n",
       " 'tf__ngram_range': (1, 2),\n",
       " 'tf__use_idf': True}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the best parameter for the model\n",
    "gs_mnnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.8690548780487805\n",
      "Test score:  0.83493369913123\n"
     ]
    }
   ],
   "source": [
    "print('Train score: ', gs_mnnb.score(x_train, y_train))\n",
    "print('Test score: ', gs_mnnb.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      1842\n",
      "           1       0.84      0.90      0.87      2532\n",
      "\n",
      "    accuracy                           0.84      4374\n",
      "   macro avg       0.84      0.83      0.84      4374\n",
      "weighted avg       0.84      0.84      0.84      4374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_predict = gs_mnnb.predict(x_test)\n",
    "print(classification_report(y_test, NB_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = Pipeline(steps=[('tf', TfidfVectorizer()), ('LR', LogisticRegression())])\n",
    "\n",
    "# Create Parameter Grid\n",
    "pgrid_lr = {\n",
    "#  'tf__max_features' : [1000, 2000, 3000],\n",
    "#  'tf__stop_words' : ['english', None],\n",
    "#  'tf__ngram_range' : [(1,1),(1,2)],\n",
    "#  'tf__use_idf' : [True, False],\n",
    " 'LR__C' : [0.9, 1.0, 0.1],\n",
    "    'LR__max_iter':[100,200,500],\n",
    "    'LR__penalty':['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Apply GridSearch to Pipeline to find the best parameters\n",
    "gs_lr = GridSearchCV(lg, pgrid_lr, cv=5, n_jobs=-1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91784\\.conda\\envs\\H_review\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.84359756        nan 0.84359756        nan 0.84359756\n",
      "        nan 0.84443598        nan 0.84443598        nan 0.84443598\n",
      "        nan 0.80480183        nan 0.80480183        nan 0.80480183]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'LR__C': [0.9, 1.0, 0.1],\n",
       "                         'LR__max_iter': [100, 200, 500],\n",
       "                         'LR__penalty': ['l1', 'l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR__C': 1.0, 'LR__max_iter': 100, 'LR__penalty': 'l2'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9078506097560975\n",
      "Test score:  0.8529949702789209\n"
     ]
    }
   ],
   "source": [
    "print('Train score: ', gs_lr.score(x_train, y_train))\n",
    "print('Test score: ', gs_lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      1842\n",
      "           1       0.86      0.90      0.88      2532\n",
      "\n",
      "    accuracy                           0.85      4374\n",
      "   macro avg       0.85      0.84      0.85      4374\n",
      "weighted avg       0.85      0.85      0.85      4374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict test cases\n",
    "lr_predict = gs_lr.predict(x_test)\n",
    "print(classification_report(y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-b12dc5135789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating a pickle file for the CountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf-transform.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a pickle file for the CountVectorizer\n",
    "pickle.dump(cv, open('tfidf-transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'Model/LG_model.pkl'\n",
    "joblib.dump(gs_lr, filename)\n",
    " \n",
    "# load the model from disk\n",
    "LG_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier - \n",
    "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_SGD = Pipeline(steps=[('tf', TfidfVectorizer()), ('SGD', SGDClassifier())])\n",
    "\n",
    "# Create Parameter Grid\n",
    "pgrid_SGD = {\n",
    "#  'tf__max_features' : [1000, 5000, 6000],\n",
    "#  'tf__stop_words' : ['english', None],\n",
    "#  'tf__ngram_range' : [(1,1),(1,2), (2,2)],\n",
    "#  'tf__use_idf' : [True, False],\n",
    " 'SGD__loss' : ['hinge', 'log', 'perceptron'],\n",
    "    'SGD__alpha': [0.00001, 0.00001, 0.0001, 0.001],\n",
    "    'SGD__max_iter' : [200, 500, 700, 1000]\n",
    "}\n",
    "\n",
    "# Apply GridSearch to Pipeline to find the best parameters\n",
    "gs_SGD = GridSearchCV(pipe_SGD, pgrid_SGD, cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Wall time: 53.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('SGD', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'SGD__alpha': [1e-05, 1e-05, 0.0001, 0.001],\n",
       "                         'SGD__loss': ['hinge', 'log', 'perceptron'],\n",
       "                         'SGD__max_iter': [200, 500, 700, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time%\n",
    "gs_SGD.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SGD__alpha': 0.0001, 'SGD__loss': 'log', 'SGD__max_iter': 500}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_SGD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9009908536585366\n",
      "Train score:  0.8511659807956105\n"
     ]
    }
   ],
   "source": [
    "print('Train score: ',gs_SGD.score(x_train, y_train))\n",
    "print('Train score: ',gs_SGD.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# # save the model to disk\n",
    "# filename = 'NB_model.sav'\n",
    "# joblib.dump(gs_mnnb, filename)\n",
    " \n",
    "# # load the model from disk\n",
    "# NB_model = joblib.load(filename)\n",
    "# # result = loaded_model.score(X_test, Y_test)\n",
    "# # print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-H_review]",
   "language": "python",
   "name": "conda-env-.conda-H_review-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
